import os
import asyncio
import logging
import sys

from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import CommandStart
from aiogram.types import ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove
from aiogram.enums import ParseMode
from aiogram.client.default import DefaultBotProperties

from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, AIMessage
from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver

# Import local modules
from engine import get_graph, AgentState
from database import db, DATABASE_URL

# Setup Logging
logging.basicConfig(level=logging.INFO, stream=sys.stdout)
logger = logging.getLogger(__name__)

# Load Env
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

if not BOT_TOKEN:
    logger.error("TELEGRAM_BOT_TOKEN not found in .env")
    sys.exit(1)

# Initialize Bot and Dispatcher
bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()

# Global checkpointer variable
checkpointer = None

# --- UTILS ---
def format_progress_message(state_update: dict, current_text: str) -> str:
    """Updates the status message based on what nodes just finished."""
    new_text = current_text

    # Check for outputs and append checkboxes
    if "triz_out" in state_update:
        new_text += "\n‚úÖ –¢–†–ò–ó —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∏–¥–µ—é"
    if "system_out" in state_update:
        new_text += "\n‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"
    if "critic_out" in state_update:
        new_text += "\n‚úÖ –†–∏—Å–∫–∏ –æ—Ü–µ–Ω–µ–Ω—ã"
    if "research_output" in state_update:
        new_text += "\n‚úÖ –§–∞–∫—Ç—ã –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã"

    return new_text

# --- HANDLERS ---

@dp.message(CommandStart())
async def cmd_start(message: types.Message):
    user = message.from_user
    # Register in DB
    try:
        db_user = await db.register_or_update_user(
            telegram_id=user.id,
            username=user.username,
            full_name=user.full_name
        )
        logger.info(f"User {user.id} registered/updated.")
    except Exception as e:
        logger.error(f"DB Error: {e}")
        await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.")
        return

    welcome_text = (
        f"–ü—Ä–∏–≤–µ—Ç, <b>{user.first_name}</b>! üëã\n\n"
        "–Ø ‚Äî Epistemic Engine v3.0. –Ø –ø–æ–º–æ–≥—É —Ç–µ–±–µ —Ä–µ—à–∏—Ç—å —Å–ª–æ–∂–Ω—É—é –±–∏–∑–Ω–µ—Å-–∑–∞–¥–∞—á—É, "
        "–∏—Å–ø–æ–ª—å–∑—É—è –¢–†–ò–ó, –°–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ.\n\n"
        "–ü—Ä–æ—Å—Ç–æ –æ–ø–∏—à–∏ —Å–≤–æ—é –ø—Ä–æ–±–ª–µ–º—É, –∏ —è –∑–∞–ø—É—â—É –∫–æ–º–∞–Ω–¥—É –∞–≥–µ–Ω—Ç–æ–≤."
    )
    await message.answer(welcome_text)

@dp.message()
async def handle_message(message: types.Message):
    user_id = message.from_user.id
    query = message.text

    # 1. Update User Activity
    await db.register_or_update_user(user_id, message.from_user.username, message.from_user.full_name)

    # 2. Prepare Graph
    # Use the persistent connection pool from global checkpointer
    graph = get_graph(checkpointer=checkpointer)

    config = {"configurable": {"thread_id": str(user_id)}}

    # Check existing state to see if we have context
    # (Optional: Logic to clear history could go here)

    # 3. Send "Thinking" message
    status_msg = await message.answer("üß† <b>–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–¥–∞—á—É...</b>")

    # 4. Stream Graph Execution
    final_verdict = ""
    last_valid_task = "" # Logic to track task similar to CLI

    # We need to construct the input state.
    # If it's a new conversation, we send messages. If continuing, LangGraph handles history via thread_id.

    # However, to pass the *new* message, we must provide it.
    input_state = {
        "messages": [HumanMessage(content=query)],
        "user_query": query,
        # We might need to fetch previous state to get 'original_task' if this is a RETRY
        # For simplicity, we pass empty original_task, assuming the graph state persistence handles context
        # But wait, 'original_task' is in the state schema.
        # If the checkpointer is working, 'original_task' from previous run is preserved if we don't overwrite it?
        # Actually, LangGraph merges input with current state.
    }

    try:
        async for event in graph.astream(input_state, config, stream_mode="values"):
            # 'event' is the full state at that point in time

            # Detect Node Completion by checking if fields are non-empty and differ from "last seen"?
            # Simpler approach: Just reconstruct the status message based on what's present.

            progress_text = "üß† <b>–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–∞–¥–∞—á—É...</b>"

            if event.get("mode"):
                mode = event["mode"]
                if mode == "CHITCHAT":
                    # Chitchat ends immediately usually
                    pass
                elif mode != "SOLVER":
                    progress_text += f"\nüëâ –†–µ–∂–∏–º: {mode}"

            if event.get("triz_out"): progress_text += "\n‚úÖ –¢–†–ò–ó —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∏–¥–µ—é"
            if event.get("system_out"): progress_text += "\n‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω"
            if event.get("critic_out"): progress_text += "\n‚úÖ –†–∏—Å–∫–∏ –æ—Ü–µ–Ω–µ–Ω—ã"
            if event.get("research_output"): progress_text += "\nüîç –§–∞–∫—Ç—ã –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã"

            # Avoid editing if text hasn't changed to prevent API limits
            if status_msg.text != progress_text.replace("<b>", "").replace("</b>", ""): # Rough check
                 # Actual check needs to be more robust against HTML parsing, but aiogram handles text equality?
                 # Let's just try-except edit
                 try:
                     if progress_text != status_msg.html_text: # aiogram 3.x property
                        await status_msg.edit_text(progress_text)
                 except:
                     pass

            # Capture verdict
            if event.get("final_verdict"):
                final_verdict = event["final_verdict"]

            # Capture mode for immediate response
            if event.get("mode") == "CHITCHAT" and not final_verdict:
                # Need to grab the last AIMessage?
                # The orchestrator sets mode CHITCHAT but doesn't generate the text?
                # Ah, in original main.py: if mode == "CHITCHAT": response = "..."
                # We need to handle this.
                pass

        # 5. Final Output
        # Delete progress message or keep it? Usually keep as log.

        currentState = await graph.get_state(config)
        state_values = currentState.values
        mode = state_values.get("mode")

        if mode == "CHITCHAT":
            await message.answer("ü§ñ –ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ—Ç–æ–≤ —Ä–µ—à–∞—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏. –í–≤–µ–¥–∏ —Å–≤–æ–π –±–∏–∑–Ω–µ—Å-–∑–∞–ø—Ä–æ—Å.")

        elif final_verdict:
            # HTML Formatting
            # Replace markdown bold **text** with <b>text</b> if needed, or rely on aiogram's Markdown parser?
            # User asked for HTML. LLM generates Markdown.
            # Simple heuristic: Let's use aiogram's Markdown parser for the verdict, it's safer than converting.
            # But we promised HTML structure for the "thinking" parts.

            # Let's send the verdict as Markdown
            await message.answer(final_verdict, parse_mode=ParseMode.MARKDOWN)

            # Optional: Send specific agent outputs in expandable blocks if requested
            # Telegram doesn't support "expandable" blocks in standard messages yet (only spoilers).
            # We can use spoilers || hidden text ||.

            details = (
                f"<b>–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏:</b>\n\n"
                f"üí° <b>–¢–†–ò–ó:</b> <tg-spoiler>{state_values.get('triz_out', '')}</tg-spoiler>\n\n"
                f"üõ°Ô∏è <b>–ö—Ä–∏—Ç–∏–∫:</b> <tg-spoiler>{state_values.get('critic_out', '')}</tg-spoiler>"
            )
            await message.answer(details)

    except Exception as e:
        logger.error(f"Graph Error: {e}")
        await message.answer(f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")


# --- STARTUP ---
async def on_startup():
    global checkpointer

    # Init DB
    await db.init_db()

    # Init Checkpointer
    # We use the same connection string logic
    conn_string = DATABASE_URL.replace("+asyncpg", "") # AsyncPostgresSaver uses psycopg logic?
    # Wait, langgraph-checkpoint-postgres documentation says:
    # AsyncPostgresSaver.from_conn_string("postgresql://user:pass@host:5432/db")
    # Our URL has +asyncpg which might confuse it if it uses psycopg3 directly or asyncpg.
    # Documentation says it uses `psycopg-pool`.
    # Let's stick to standard postgres:// scheme for it if needed, but asyncpg scheme usually works for async libs.
    # Let's try passing the pool or connection string.

    # Actually, let's create the pool manually to be safe or use from_conn_string
    # Fix: AsyncPostgresSaver requires 'postgresql://' scheme, not 'postgresql+asyncpg://'
    checkpointer = AsyncPostgresSaver.from_conn_string(conn_string)

    # Need to call setup to create checkpoint tables
    # Note: from_conn_string is a context manager or returns an object?
    # In async it's usually `async with ...`.
    # But we need it to persist across requests.

    # Correct pattern:
    # async with AsyncPostgresSaver.from_conn_string(...) as checkpointer:
    #    ...
    # But we are in a long-running app.

    # We will instantiate it here.
    # NOTE: AsyncPostgresSaver needs to be entered (aentered) to set up the connection pool.
    await checkpointer.__aenter__()
    await checkpointer.setup()

async def on_shutdown():
    if checkpointer:
        await checkpointer.__aexit__(None, None, None)

# --- MAIN ---
async def main():
    dp.startup.register(on_startup)
    dp.shutdown.register(on_shutdown)
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
